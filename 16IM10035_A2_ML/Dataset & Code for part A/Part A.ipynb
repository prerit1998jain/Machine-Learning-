{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep= ',', header = None)\n",
    "test = pd.read_csv('test.csv', sep= ',', header = None)\n",
    "train = (train[1:len(train)][:])\n",
    "test = (test[1:len(test)][:])\n",
    "train = train.apply(LabelEncoder().fit_transform)\n",
    "test = test.apply(LabelEncoder().fit_transform)\n",
    "#print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.values[:,0:3]\n",
    "#print(X_train)\n",
    "Y_train = train.values[:,4]\n",
    "X_test = test.values[:,0:3]\n",
    "Y_test = test.values[:,4]\n",
    "train = list(np.concatenate((X_train,np.reshape((Y_train),(len(X_train),1))),axis = 1))\n",
    "test = list(np.concatenate((X_test,np.reshape((Y_test),(len(X_test),1))),axis = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scikit Learn Library for classifcation\n",
    "def train_using_gini(X_train, y_train):\n",
    "    # Creating the classifier object \n",
    "    dectree_gini = DecisionTreeClassifier(criterion = \"gini\") \n",
    "    # Performing training \n",
    "    dectree_gini.fit(X_train, y_train) \n",
    "    return dectree_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_using_entropy(X_train,Y_train):\n",
    "    dectree_entropy = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "    dectree_entropy.fit(X_train,Y_train)\n",
    "    return(dectree_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X_test, model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Predicted Values:\")\n",
    "    print(y_pred)\n",
    "    return(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(y_test, y_pred):\n",
    "    print(\"Confusion Matrix: \\n \", confusion_matrix(y_test,y_pred))\n",
    "    print(\"Accuracy: \\n\", accuracy_score(y_test,y_pred))\n",
    "    print(\"Classification_Report: \\n\", classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values through decision tree using gini index as a crtieria \n",
      "\n",
      "Predicted Values:\n",
      "[0 1]\n",
      "Confusion Matrix: \n",
      "  [[1 1]\n",
      " [0 0]]\n",
      "Accuracy: \n",
      " 0.5\n",
      "Classification_Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.25      0.33         2\n",
      "weighted avg       1.00      0.50      0.67         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prerit/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dec_tree_gini = train_using_gini(X_train, Y_train)\n",
    "print(\"The predicted values through decision tree using gini index as a crtieria \\n\")\n",
    "y_pred_gini = prediction(X_test, dec_tree_gini)\n",
    "cal_accuracy(Y_test,y_pred_gini)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values through decision tree using entropy as a crtieria \n",
      "\n",
      "Predicted Values:\n",
      "[0 1]\n",
      "Confusion Matrix: \n",
      "  [[1 1]\n",
      " [0 0]]\n",
      "Accuracy: \n",
      " 0.5\n",
      "Classification_Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.25      0.33         2\n",
      "weighted avg       1.00      0.50      0.67         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prerit/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dec_tree_entropy = train_using_entropy(X_train, Y_train)\n",
    "\n",
    "print(\"The predicted values through decision tree using entropy as a crtieria \\n\")\n",
    "y_pred_entropy = prediction(X_test, dec_tree_entropy)\n",
    "#print(train.apply(LabelEncoder().inverse_transform))\n",
    "\n",
    "cal_accuracy(Y_test,y_pred_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "##########################################################################\n",
    "## Writing Decision tree from scratch without using any python library  ##\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "### Creating a split on the basis of an attribute ###\n",
    "def split_data(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index]==value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return( left, right)\n",
    "\n",
    "\n",
    "### Computing\n",
    "def gini_index(splits,values):\n",
    "    total_count = sum([len(split) for split in splits])\n",
    "    gini = 0.0\n",
    "    for split in splits:\n",
    "        size = len(split)\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0\n",
    "        for value in values:\n",
    "            score += pow(([row[-1] for row in split].count(value)/size),2)\n",
    "        gini += (1-score)*(size/total_count)\n",
    "    return(gini)\n",
    "\n",
    "def entropy(splits,values):\n",
    "    total_count = sum([len(split) for split in splits])\n",
    "    entropy = 0\n",
    "    for split in splits:\n",
    "        size = len(split)\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0\n",
    "        for value in values:\n",
    "            entropy += ([row[-1] for row in split].count(value)/size)*np.log2(([row[-1] for row in split].count(value)/size))\n",
    "        gain += -1*(entropy)*(size/total_count)\n",
    "    return(gain)\n",
    "\n",
    "def get_best_split_entropy(dataset): \n",
    "    y_label = list(set(row[-1] for row in dataset))\n",
    "    best_index,best_value,best_score,best_splits = 99,99,99,None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for i in range(2):\n",
    "            splits = split_data(index,i,dataset)\n",
    "            entropy = entropy(splits,y_label)\n",
    "            if entropy > best_score:\n",
    "                best_index = index\n",
    "                best_value = i\n",
    "                best_score = gini\n",
    "                best_splits = splits\n",
    "    return{'index':best_index,'value':best_value,'best_score':best_score,'splits':best_splits}\n",
    "\n",
    "\n",
    "def get_best_split_gini(dataset): \n",
    "    y_label = list(set(row[-1] for row in dataset))\n",
    "    best_index,best_value,best_score,best_splits = 99,99,99,None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for i in range(2):\n",
    "            splits = split_data(index,i,dataset)\n",
    "            gini = gini_index(splits,y_label)\n",
    "            if gini < best_score:\n",
    "                best_index = index\n",
    "                best_value = i\n",
    "                best_score = gini\n",
    "                best_splits = splits\n",
    "    print(\"The best gini index for this node is\", best_score)\n",
    "    return{'index':best_index,'value':best_value,'best_score':best_score,'splits':best_splits}\n",
    "\n",
    "    \n",
    "def output_majority_class(split):\n",
    "    y_label = [row[-1] for row in split]\n",
    "    return(max(set(y_label), key = y_label.count))\n",
    "\n",
    "def recursive_splitting_gini(node, max_depth,depth): \n",
    "    left, right = node['splits']\n",
    "    del(node['splits'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = output_majority_class(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = output_majority_class(left),output_majority_class(right)\n",
    "        return\n",
    "    else:\n",
    "        node['left'] = get_best_split_gini(left)\n",
    "        recursive_splitting_gini(node['left'], max_depth,depth+1)\n",
    "        node['right'] = get_best_split_gini(right)\n",
    "        recursive_splitting_gini(node['right'], max_depth, depth+1)\n",
    "        \n",
    "        \n",
    "def recursive_splitting_entropy(node, max_depth,depth): \n",
    "    left, right = node['splits']\n",
    "    del(node['splits'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = output_majority_class(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = output_majority_class(left),output_majority_class(right)\n",
    "        return\n",
    "    else:\n",
    "        node['left'] = get_best_split_entropy(left)\n",
    "        recursive_splitting_entropy(node['left'], max_depth,depth+1)\n",
    "        node['right'] = get_best_split_entropy(right)\n",
    "        recursive_splitting_entropy(node['right'], max_depth, depth+1)\n",
    "\n",
    "def build_tree_gini(train, max_depth):\n",
    "    root = get_best_split_gini(train)\n",
    "    recursive_splitting_gini(root, max_depth,1)\n",
    "    return(root)\n",
    "\n",
    "def build_tree_entropy(train, max_depth):\n",
    "    root = get_best_split_entropy(train)\n",
    "    recursive_splitting_entropy(root, max_depth,1)\n",
    "    return(root)\n",
    "    \n",
    "def print_tree(node, depth=0):\n",
    "\tif isinstance(node, dict):\n",
    "\t\tprint('%s|X%d = %d' % ((depth*'\\t', (node['index']+1), int(node['value']))))\n",
    "\t\tprint_tree(node['left'], depth+1)\n",
    "\t\tprint_tree(node['right'], depth+1)\n",
    "\telse:\n",
    "\t\tprint('%s:[%s]' % ((depth*'\\t', node)))\n",
    "    \n",
    "\n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    "\n",
    "def prediction(test,tree):\n",
    "    y_pred = []\n",
    "    for row in test:\n",
    "        y_pred.append(predict(tree,row))\n",
    "    return(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best gini index for this node is 0.41666666666666663\n",
      "The best gini index for this node is 0.0\n",
      "The best gini index for this node is 0.3666666666666666\n",
      "The best gini index for this node is 0.0\n",
      "The best gini index for this node is 0.0\n",
      "The best gini index for this node is 0.0\n",
      "The best gini index for this node is 0.26666666666666666\n",
      "The best gini index for this node is 0.0\n",
      "The best gini index for this node is 0.3333333333333333\n",
      "|X2 = 1\n",
      "\t|X1 = 0\n",
      "\t\t:[1]\n",
      "\t\t:[1]\n",
      "\t|X1 = 0\n",
      "\t\t|X3 = 0\n",
      "\t\t\t|X1 = 0\n",
      "\t\t\t\t:[0]\n",
      "\t\t\t\t:[0]\n",
      "\t\t\t|X1 = 0\n",
      "\t\t\t\t:[1]\n",
      "\t\t\t\t:[1]\n",
      "\t\t|X1 = 1\n",
      "\t\t\t|X1 = 0\n",
      "\t\t\t\t:[0]\n",
      "\t\t\t\t:[0]\n",
      "\t\t\t|X2 = 0\n",
      "\t\t\t\t:[0]\n",
      "\t\t\t\t:[0]\n",
      "Confusion Matrix: \n",
      "  [[1 0]\n",
      " [1 0]]\n",
      "Accuracy: \n",
      " 0.5\n",
      "Classification_Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "tree_gini = build_tree_gini(train,4)\n",
    "print_tree(tree_gini)\n",
    "type(test)\n",
    "y_pred = prediction(test,tree_gini)\n",
    "cal_accuracy(y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
