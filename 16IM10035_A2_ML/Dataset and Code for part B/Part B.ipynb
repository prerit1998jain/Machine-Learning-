{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reading the txt file and storing the data into a list of list.\n",
    "def read_dataset(file_X,file_Y):\n",
    "    list_of_lists = []\n",
    "    with open(file_X,'r') as f:\n",
    "        for line in f:\n",
    "            inner_list = [elt.strip() for elt in line.split('\\t')]\n",
    "            list_of_lists.append(inner_list)\n",
    "    data = np.asarray(list_of_lists,dtype = int)\n",
    "    X_train = np.zeros(np.max(data,axis = 0))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(1):\n",
    "            doc_id = data[i][j]\n",
    "            word_id = data[i][j+1]\n",
    "            X_train[doc_id-1][word_id-1]=1\n",
    "    train_label = open(file_Y,'r').readlines()\n",
    "    Y_train = np.asarray(train_label,dtype = int)\n",
    "    return(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train = read_dataset('traindata.txt','trainlabel.txt')\n",
    "X_test, Y_test = read_dataset('testdata.txt','testlabel.txt')\n",
    "# Equating the number of columns in test and train set\n",
    "X_test = X_test[:,0:np.shape(X_train)[1]]\n",
    "\n",
    "train = list(np.concatenate((X_train,np.reshape((Y_train),(len(X_train),1))),axis = 1))\n",
    "test = list(np.concatenate((X_test,np.reshape((Y_test),(len(X_test),1))),axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scikit Learn Library for classifcation\n",
    "def train_using_gini(X_train, y_train, max_depth):\n",
    "    # Creating the classifier object \n",
    "    dectree_gini = DecisionTreeClassifier(criterion = \"gini\",max_depth= max_depth) \n",
    "    # Performing training \n",
    "    dectree_gini.fit(X_train, y_train) \n",
    "    return dectree_gini\n",
    "\n",
    "# Using Entropy\n",
    "def train_using_entropy(X_train,y_train,max_depth):\n",
    "    dectree_entropy = DecisionTreeClassifier(criterion = 'entropy',max_depth = max_depth)\n",
    "    dectree_entropy.fit(X_train,y_train)\n",
    "    return(dectree_entropy)\n",
    "\n",
    "# Prediction on the basis of the model\n",
    "def prediction(X_test,model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return(y_pred)\n",
    "\n",
    "#calculating accuracy and other metrics\n",
    "def cal_accuracy(y_test, y_pred):\n",
    "    print(\"Confusion Matrix: \\n \", confusion_matrix(y_test,y_pred))\n",
    "    print(\"Accuracy: \\n\", accuracy_score(y_test,y_pred))\n",
    "    print(\"Classification_Report: \\n\", classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function for Decision tree using scikit learn package from python\n",
    "def DecisionTree_using_scikitlearn(X_train,Y_train,method,max_depth):\n",
    "    if method == 'gini_index':\n",
    "        dec_tree_gini = train_using_gini(X_train, Y_train,max_depth)\n",
    "        return(dec_tree_gini)\n",
    "    if method == 'entropy':\n",
    "        dec_tree_entropy = train_using_entropy(X_train, Y_train,max_depth)\n",
    "        return(dec_tree_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################# \n",
      " The following results are obtained using the scikit learn package \n",
      " ################################################################## \n",
      "\n",
      "The predicted values through decision tree using gini index as a crtieria \n",
      "\n",
      "Confusion Matrix: \n",
      "  [[230  88]\n",
      " [ 38 351]]\n",
      "Accuracy: \n",
      " 0.8217821782178217\n",
      "Classification_Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.72      0.78       318\n",
      "           2       0.80      0.90      0.85       389\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       707\n",
      "   macro avg       0.83      0.81      0.82       707\n",
      "weighted avg       0.83      0.82      0.82       707\n",
      "\n",
      "The predicted values through decision tree using entropy as a crtieria \n",
      "\n",
      "Confusion Matrix: \n",
      "  [[227  91]\n",
      " [ 39 350]]\n",
      "Accuracy: \n",
      " 0.8161244695898161\n",
      "Classification_Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.71      0.78       318\n",
      "           2       0.79      0.90      0.84       389\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       707\n",
      "   macro avg       0.82      0.81      0.81       707\n",
      "weighted avg       0.82      0.82      0.81       707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"################################################################# \\n\",\n",
    "     \"The following results are obtained using the scikit learn package \\n\",\n",
    "     \"################################################################## \\n\")\n",
    "\n",
    "\n",
    "print(\"The predicted values through decision tree using gini index as a crtieria \\n\")\n",
    "y_pred_gini = prediction(X_test, DecisionTree_using_scikitlearn(X_train,Y_train,'gini_index',5))\n",
    "cal_accuracy(Y_test,y_pred_gini)\n",
    "    \n",
    "print(\"The predicted values through decision tree using entropy as a crtieria \\n\")\n",
    "y_pred_entropy = prediction(X_test, DecisionTree_using_scikitlearn(X_train,Y_train,'entropy',5))\n",
    "cal_accuracy(Y_test,y_pred_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "##########################################################################\n",
    "## Writing Decision tree from scratch without using any python library  ##\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "### Creating a split on the basis of an attribute ###\n",
    "def split_data(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index]==value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return( left, right)\n",
    "\n",
    "\n",
    "### Computing\n",
    "def gini_index(splits,values):\n",
    "    total_count = sum([len(split) for split in splits])\n",
    "    gini = 0.0\n",
    "    for split in splits:\n",
    "        size = len(split)\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0\n",
    "        for value in values:\n",
    "            score += pow(([row[-1] for row in split].count(value)/size),2)\n",
    "        gini += (1-score)*(size/total_count)\n",
    "    return(gini)\n",
    "\n",
    "def entropy(splits,values):\n",
    "    total_count = sum([len(split) for split in splits])\n",
    "    entropy = 0\n",
    "    for split in splits:\n",
    "        size = len(split)\n",
    "        if size == 0:\n",
    "            continue\n",
    "        entropy_score = 0\n",
    "        gain = 0\n",
    "        for value in values:\n",
    "            entropy_score += ([row[-1] for row in split].count(value)/size)*np.log2(([row[-1] for row in split].count(value)/size))\n",
    "        gain += -1*(entropy_score)*(size/total_count)\n",
    "    return(gain)\n",
    "\n",
    "def get_best_split_entropy(dataset): \n",
    "    y_label = list(set(row[-1] for row in dataset))\n",
    "    best_index,best_value,best_score,best_splits = 99,99,99,None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for i in range(2):\n",
    "            splits = split_data(index,i,dataset)\n",
    "            entropy_score = entropy(splits,y_label)\n",
    "            if entropy_score > best_score:\n",
    "                best_index = index\n",
    "                best_value = i\n",
    "                best_score = gini\n",
    "                best_splits = splits\n",
    "    return{'index':best_index,'value':best_value,'best_score':best_score,'splits':best_splits}\n",
    "\n",
    "\n",
    "def get_best_split_gini(dataset): \n",
    "    y_label = list(set(row[-1] for row in dataset))\n",
    "    best_index,best_value,best_score,best_splits = 99,99,99,None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for i in range(2):\n",
    "            splits = split_data(index,i,dataset)\n",
    "            gini = gini_index(splits,y_label)\n",
    "            if gini < best_score:\n",
    "                best_index = index\n",
    "                best_value = i\n",
    "                best_score = gini\n",
    "                best_splits = splits\n",
    "    print(\"Gini Index of best split is\", best_score)\n",
    "    return{'index':best_index,'value':best_value,'best_score':best_score,'splits':best_splits}\n",
    "\n",
    "    \n",
    "def output_majority_class(split):\n",
    "    y_label = [row[-1] for row in split]\n",
    "    return(max(set(y_label), key = y_label.count))\n",
    "\n",
    "def recursive_splitting_gini(node, max_depth,depth): \n",
    "    left, right = node['splits']\n",
    "    del(node['splits'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = output_majority_class(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = output_majority_class(left),output_majority_class(right)\n",
    "        return\n",
    "    else:\n",
    "        node['left'] = get_best_split_gini(left)\n",
    "        recursive_splitting_gini(node['left'], max_depth,depth+1)\n",
    "        node['right'] = get_best_split_gini(right)\n",
    "        recursive_splitting_gini(node['right'], max_depth, depth+1)\n",
    "        \n",
    "        \n",
    "def recursive_splitting_entropy(node, max_depth,depth): \n",
    "    left, right = node['splits']\n",
    "    del(node['splits'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = output_majority_class(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = output_majority_class(left),output_majority_class(right)\n",
    "        return\n",
    "    else:\n",
    "        node['left'] = get_best_split_entropy(left)\n",
    "        recursive_splitting_entropy(node['left'], max_depth,depth+1)\n",
    "        node['right'] = get_best_split_entropy(right)\n",
    "        recursive_splitting_entropy(node['right'], max_depth, depth+1)\n",
    "\n",
    "def build_tree_gini(train, max_depth):\n",
    "    root = get_best_split_gini(train)\n",
    "    recursive_splitting_gini(root, max_depth,1)\n",
    "    return(root)\n",
    "\n",
    "def build_tree_entropy(train, max_depth):\n",
    "    root = get_best_split_entropy(train)\n",
    "    recursive_splitting_entropy(root, max_depth,1)\n",
    "    return(root)\n",
    "    \n",
    "def print_tree(node, depth=0):\n",
    "\tif isinstance(node, dict):\n",
    "\t\tprint('%s|X%d = %d' % ((depth*'\\t', (node['index']+1), int(node['value']))))\n",
    "\t\tprint_tree(node['left'], depth+1)\n",
    "\t\tprint_tree(node['right'], depth+1)\n",
    "\telse:\n",
    "\t\tprint('%s:[%s]' % ((depth*'\\t', node)))\n",
    "    \n",
    "\n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    "\n",
    "def prediction(test,tree):\n",
    "    y_pred = []\n",
    "    for row in test:\n",
    "        y_pred.append(predict(tree,row))\n",
    "    return(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Index of best split is 0.3548256049128906\n",
      "Gini Index of best split is 0.2660858470997732\n",
      "Gini Index of best split is 0.2446462652506112\n",
      "Gini Index of best split is 0.06048387096774179\n",
      "Gini Index of best split is 0.3184158945117606\n",
      "Gini Index of best split is 0.2905290018647561\n",
      "Gini Index of best split is 0.0\n",
      "|X485 = 0\n",
      "\t|X212 = 0\n",
      "\t\t|X153 = 0\n",
      "\t\t\t:[2.0]\n",
      "\t\t\t:[2.0]\n",
      "\t\t|X510 = 0\n",
      "\t\t\t:[1.0]\n",
      "\t\t\t:[2.0]\n",
      "\t|X3143 = 0\n",
      "\t\t|X2109 = 0\n",
      "\t\t\t:[1.0]\n",
      "\t\t\t:[2.0]\n",
      "\t\t|X1 = 0\n",
      "\t\t\t:[2.0]\n",
      "\t\t\t:[2.0]\n",
      "Confusion Matrix: \n",
      "  [[  0   0]\n",
      " [318 389]]\n",
      "Accuracy: \n",
      " 0.5502121640735502\n",
      "Classification_Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "         2.0       1.00      0.55      0.71       707\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       707\n",
      "   macro avg       0.50      0.28      0.35       707\n",
      "weighted avg       1.00      0.55      0.71       707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "tree_gini = build_tree_gini(train,3)\n",
    "print_tree(tree_gini)\n",
    "type(test)\n",
    "y_pred = prediction(test,tree_gini)\n",
    "cal_accuracy(y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
